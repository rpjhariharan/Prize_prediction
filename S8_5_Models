1. Linear Regression

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, cross_val_score

# Load Dataset
file_path = r'D:\OneDrive\Desktop\Car\Cleaned\Feature_Engineered_Car_Dataset.csv'
car_data = pd.read_csv(file_path)

# Define Features and Target
X = car_data.drop(columns=['Price'])
y = car_data['Price']

# Split Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train Model
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)

# Predict
y_train_pred = linear_model.predict(X_train)
y_test_pred = linear_model.predict(X_test)

# Metrics
train_mae = mean_absolute_error(y_train, y_train_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

# Cross-Validation
cv_scores = cross_val_score(linear_model, X, y, cv=5, scoring='r2')

# Results
print("Linear Regression Results:")
print("Train MAE:", train_mae, "Test MAE:", test_mae)
print("Train R²:", train_r2, "Test R²:", test_r2)
print("Train RMSE:", train_rmse, "Test RMSE:", test_rmse)
print("CV Mean R²:", cv_scores.mean(), "CV Std R²:", cv_scores.std()) 


Linear Regression Results:
Train MAE: 271237.845089428      Test MAE: 273374.8420486624
Train R²: 0.743014054401487      Test R²: 0.7028211340655481
Train RMSE: 538115.8772033883    Test RMSE: 573596.1074647482
CV Mean R²: 0.6941358364545447   CV Std R²: 0.039414358227388764



2. Decision Tree Regressor

import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, cross_val_score

# Load Dataset
file_path = r'D:\OneDrive\Desktop\Car\Cleaned\Feature_Engineered_Car_Dataset.csv'
car_data = pd.read_csv(file_path)

# Define Features and Target
X = car_data.drop(columns=['Price'])
y = car_data['Price']

# Split Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train Model
tree_model = DecisionTreeRegressor(random_state=42)
tree_model.fit(X_train, y_train)

# Predict
y_train_pred = tree_model.predict(X_train)
y_test_pred = tree_model.predict(X_test)

# Metrics
train_mae = mean_absolute_error(y_train, y_train_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

# Cross-Validation
cv_scores = cross_val_score(tree_model, X, y, cv=5, scoring='r2')

# Results
print("Decision Tree Results:")
print("Train MAE:", train_mae, "Test MAE:", test_mae)
print("Train R²:", train_r2, "Test R²:", test_r2)
print("Train RMSE:", train_rmse, "Test RMSE:", test_rmse)
print("CV Mean R²:", cv_scores.mean(), "CV Std R²:", cv_scores.std()) 

Decision Tree Regressor
Train R²: 1.00 (overfitting likely)
Test R²: ~0.74
Train RMSE: 0
Test RMSE: 422,774
Train MAE: 0
Test MAE: 211,090
CV Mean R²: ~0.73
CV Std R²: ~0.06





3. Random Forest Regressor

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, cross_val_score

# Load Dataset
file_path = r'D:\OneDrive\Desktop\Car\Cleaned\Feature_Engineered_Car_Dataset.csv'
car_data = pd.read_csv(file_path)

# Define Features and Target
X = car_data.drop(columns=['Price'])
y = car_data['Price']

# Split Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train Model
forest_model = RandomForestRegressor(random_state=42)
forest_model.fit(X_train, y_train)

# Predict
y_train_pred = forest_model.predict(X_train)
y_test_pred = forest_model.predict(X_test)

# Metrics
train_mae = mean_absolute_error(y_train, y_train_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

# Cross-Validation
cv_scores = cross_val_score(forest_model, X, y, cv=5, scoring='r2')

# Results
print("Random Forest Results:")
print("Train MAE:", train_mae, "Test MAE:", test_mae)
print("Train R²:", train_r2, "Test R²:", test_r2)
print("Train RMSE:", train_rmse, "Test RMSE:", test_rmse)
print("CV Mean R²:", cv_scores.mean(), "CV Std R²:", cv_scores.std())


Random Forest Regressor
Train R²: ~0.95
Test R²: ~0.89
Train RMSE: ~153,000
Test RMSE: 288,904
Train MAE: 95,000
Test MAE: 154,600
CV Mean R²: ~0.89
CV Std R²: ~0.03





4. Gradient Boosting Regressor
import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, cross_val_score


# Load Dataset
file_path = r'D:\OneDrive\Desktop\Car\Cleaned\Feature_Engineered_Car_Dataset.csv'
car_data = pd.read_csv(file_path)

# Define Features and Target
X = car_data.drop(columns=['Price'])
y = car_data['Price']

# Split Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train Model
gb_model = GradientBoostingRegressor(random_state=42)
gb_model.fit(X_train, y_train)

# Predict
y_train_pred = gb_model.predict(X_train)
y_test_pred = gb_model.predict(X_test)

# Metrics
train_mae = mean_absolute_error(y_train, y_train_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

# Cross-Validation
cv_scores = cross_val_score(gb_model, X, y, cv=5, scoring='r2')

# Results
print("Gradient Boosting Results:")
print("Train MAE:", train_mae, "Test MAE:", test_mae)
print("Train R²:", train_r2, "Test R²:", test_r2)
print("Train RMSE:", train_rmse, "Test RMSE:", test_rmse)
print("CV Mean R²:", cv_scores.mean(), "CV Std R²:", cv_scores.std())


Gradient Boosting Regressor
Train R²: ~0.93
Test R²: ~0.87
Train RMSE: ~160,000
Test RMSE: 316,267
Train MAE: 110,000
Test MAE: 167,409
CV Mean R²: ~0.87
CV Std R²: ~0.04






5. XGBoost Regressor
import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, cross_val_score


# Load Dataset
file_path = r'D:\OneDrive\Desktop\Car\Cleaned\Feature_Engineered_Car_Dataset.csv'
car_data = pd.read_csv(file_path)

# Define Features and Target
X = car_data.drop(columns=['Price'])
y = car_data['Price']

# Split Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train Model
xgb_model = XGBRegressor(random_state=42)
xgb_model.fit(X_train, y_train)

# Predict
y_train_pred = xgb_model.predict(X_train)
y_test_pred = xgb_model.predict(X_test)

# Metrics
train_mae = mean_absolute_error(y_train, y_train_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

# Cross-Validation
cv_scores = cross_val_score(xgb_model, X, y, cv=5, scoring='r2')

# Results
print("XGBoost Regressor Results:")
print("Train MAE:", train_mae, "Test MAE:", test_mae)
print("Train R²:", train_r2, "Test R²:", test_r2)
print("Train RMSE:", train_rmse, "Test RMSE:", test_rmse)
print("CV Mean R²:", cv_scores.mean(), "CV Std R²:", cv_scores.std())

XGBoost Regressor
Train R²: ~0.97
Test R²: 0.92
Train RMSE: ~130,000
Test RMSE: 265,141
Train MAE: ~95,000
Test MAE: 134,802
CV Mean R²: 0.92
CV Std R²: ~0.03




XGBoost Regressor has the highest accuracy with:

Test R²: 0.92
Test RMSE: 265,141
Test MAE: 134,802
This makes XGBoost the most reliable model for price prediction.
