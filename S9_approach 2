import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

file_path = r'D:\OneDrive\Desktop\Car\Cleaned\Cleaned_and_Adjusted_Car_Dataset.csv'
car_data = pd.read_csv(file_path)
# Selecting the relevant features and target variable
X = car_data[['Kilometers Driven', 'Car Age', 'Mileage', 'Previous Owners']]
y = car_data['Adjusted Price']

# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the parameter grid for GridSearchCV for XGBoost
param_grid_xgb = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0],
    'gamma': [0, 0.1, 0.2]
}

# Initialize XGBRegressor
xgb_model = XGBRegressor(random_state=42, objective='reg:squarederror')

# Set up GridSearchCV for XGBoost
grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb, cv=5, scoring='r2', n_jobs=-1)
grid_search_xgb.fit(X_train, y_train)

# Display best parameters from GridSearchCV
print("Best Parameters:", grid_search_xgb.best_params_)

# Retrain the model with the best parameters
best_xgb_model = grid_search_xgb.best_estimator_
best_xgb_model.fit(X_train, y_train)

# Predictions with the optimized XGBoost model
y_train_pred_xgb = best_xgb_model.predict(X_train)
y_test_pred_xgb = best_xgb_model.predict(X_test)

# Calculate performance metrics
train_mae_xgb = mean_absolute_error(y_train, y_train_pred_xgb)
test_mae_xgb = mean_absolute_error(y_test, y_test_pred_xgb)
train_r2_xgb = r2_score(y_train, y_train_pred_xgb)
test_r2_xgb = r2_score(y_test, y_test_pred_xgb)
train_rmse_xgb = mean_squared_error(y_train, y_train_pred_xgb, squared=False)
test_rmse_xgb = mean_squared_error(y_test, y_test_pred_xgb, squared=False)

# Cross-validation for R² score
cv_r2_scores_xgb = cross_val_score(best_xgb_model, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)
cv_mean_r2_xgb = np.mean(cv_r2_scores_xgb)
cv_std_r2_xgb = np.std(cv_r2_scores_xgb)

# Displaying results
print("Train MAE:", train_mae_xgb)
print("Test MAE:", test_mae_xgb)
print("Train R²:", train_r2_xgb)
print("Test R²:", test_r2_xgb)
print("Train RMSE:", train_rmse_xgb)
print("Test RMSE:", test_rmse_xgb)
print("CV Mean R²:", cv_mean_r2_xgb)
print("CV Std R²:", cv_std_r2_xgb)

xgb_model.save_model(r"D:\OneDrive\Desktop\AIasServ\python\pythonProject\xgboost_model.json")
